# BERT_my_summary

预训练的语言模型的一些总结和个人思考

语言模型的发展：n-gram, CBOW/skip-gram, transformer, bert/gpt。我们不关注目前众多的语言模型变种，只关注里程碑性质的关键论文和思想。
从这些基础出发，也可以做一些发散性的思考。

1. self-attention 优化;
2. 大模型:
3. 目标优化: 
4. 特征优化:

一些概述和最近进展:
1. https://www.topbots.com/leading-nlp-language-models-2020/
2. https://ruder.io/recent-advances-lm-fine-tuning/
3. 
参考资料:
1. Transformer: https://arxiv.org/abs/1706.03762
2. BERT: https://arxiv.org/abs/1810.04805
3. BERT官方代码：https://github.com/google-research/bert
